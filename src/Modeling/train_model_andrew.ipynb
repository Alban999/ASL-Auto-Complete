{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data labels are in the form below:\n",
    "alphabet = ['1', '2', '3','4', 'space', 'del', \n",
    "'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "labels_ = alphabet\n",
    "NUM_CLASSES = len(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = pd.read_csv(\"./data/train/x_data900.csv\") \n",
    "y_flat = pd.read_csv(\"./data/train/y_data900.csv\")  #Note the first column of this is the index, so it's nx2 size\n",
    "\n",
    "x_flat_test = pd.read_csv(\"./data/test/x_data_test100.csv\")\n",
    "y_flat_test = pd.read_csv(\"./data/test/y_data_test100.csv\") #Note the first column of this is the index, so it's nx2 size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]],\n",
       "\n",
       "       [[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]],\n",
       "\n",
       "       [[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to unflatten\n",
    "def unflatten(df,shape):\n",
    "    \"\"\" \n",
    "    reshape a dataframe to the correct array size\n",
    "    shape is an array ex [21,3] which describes the desired shape\n",
    "    \"\"\"\n",
    "    old_array = df.to_numpy()\n",
    "    new_array = []\n",
    "    for point in old_array:\n",
    "        point_reshaped = point.reshape(shape[0], shape[1])\n",
    "        new_array.append(point_reshaped)\n",
    "\n",
    "    return np.array(new_array)\n",
    "\n",
    "# TEST\n",
    "arr = np.array([[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8]])\n",
    "arr = pd.DataFrame(arr)\n",
    "unflatten(arr,shape=[2,4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (24367, 21, 3) training score's shape (24367, 1)\n",
      "testing data shape: (2659, 21, 3) testing score's shape (2659, 1)\n"
     ]
    }
   ],
   "source": [
    "#revert the data back into its original form\n",
    "x_data = unflatten(x_flat,shape=[21,3])\n",
    "X_test = unflatten(x_flat_test,shape=[21,3])\n",
    "\n",
    "#Adjust labels to numpy array\n",
    "y_data = y_flat.to_numpy()\n",
    "y_test = y_flat_test.to_numpy()\n",
    "\n",
    "print(\"training data shape:\", np.shape(x_data), \"training score's shape\", np.shape(y_data))\n",
    "print(\"testing data shape:\", np.shape(X_test), \"testing score's shape\", np.shape(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode\n",
    "y_train = to_categorical(y_train).astype(int)\n",
    "y_valid = to_categorical(y_valid).astype(int)\n",
    "y_test = to_categorical(y_test).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our models. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Our inputs are:\n",
    "- X_Train, y_train \n",
    "- X_valid, y_valid\n",
    "- X_test,y_test\n",
    "Each datapoint in the Xs are [21,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "checkpoint_path = \"./checkpoints.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(21, 3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "673/686 [============================>.] - ETA: 0s - loss: 0.1868 - categorical_accuracy: 0.9737\n",
      "Epoch 1: saving model to .\\checkpoints.ckpt\n",
      "686/686 [==============================] - 2s 3ms/step - loss: 0.1852 - categorical_accuracy: 0.9739 - val_loss: 0.1521 - val_categorical_accuracy: 0.9713\n",
      "Epoch 2/5\n",
      "672/686 [============================>.] - ETA: 0s - loss: 0.1249 - categorical_accuracy: 0.9810\n",
      "Epoch 2: saving model to .\\checkpoints.ckpt\n",
      "686/686 [==============================] - 1s 2ms/step - loss: 0.1259 - categorical_accuracy: 0.9809 - val_loss: 0.1070 - val_categorical_accuracy: 0.9852\n",
      "Epoch 3/5\n",
      "677/686 [============================>.] - ETA: 0s - loss: 0.0960 - categorical_accuracy: 0.9854\n",
      "Epoch 3: saving model to .\\checkpoints.ckpt\n",
      "686/686 [==============================] - 1s 2ms/step - loss: 0.0975 - categorical_accuracy: 0.9853 - val_loss: 0.0862 - val_categorical_accuracy: 0.9869\n",
      "Epoch 4/5\n",
      "665/686 [============================>.] - ETA: 0s - loss: 0.0808 - categorical_accuracy: 0.9873\n",
      "Epoch 4: saving model to .\\checkpoints.ckpt\n",
      "686/686 [==============================] - 2s 2ms/step - loss: 0.0813 - categorical_accuracy: 0.9874 - val_loss: 0.0676 - val_categorical_accuracy: 0.9865\n",
      "Epoch 5/5\n",
      "658/686 [===========================>..] - ETA: 0s - loss: 0.0700 - categorical_accuracy: 0.9884\n",
      "Epoch 5: saving model to .\\checkpoints.ckpt\n",
      "686/686 [==============================] - 1s 2ms/step - loss: 0.0694 - categorical_accuracy: 0.9884 - val_loss: 0.0611 - val_categorical_accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c5f160b50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, callbacks=[cp_callback],validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
